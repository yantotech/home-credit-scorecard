{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "\n",
    "Notebook ini berfungsi untuk melakukan proses pelatihan model machine learning guna meminimalkan False Negative untuk memastikan pelanggan yang layak mendapatkan pinjaman tidak salah ditolak. Adapun prosesnya meliputi hal berikut.\n",
    "1. Membaca data hasil processing (train_processed.csv) sebagai input untuk pelatihan.\n",
    "2. Melakukan scaling menggunakan RobustScaler agar distribusi fitur lebih stabil terhadap outlier.\n",
    "3. Menyeimbangkan distribusi kelas dengan teknik SMOTE (Synthetic Minority Over-sampling Technique) untuk mengatasi ketidakseimbangan data.\n",
    "4. Melatih tiga model utama, yaitu Logistic Regression, Random Forest, dan Gradient Boosting, dengan optimasi melalui GridSearchCV untuk memaksimalkan recall.\n",
    "5. Melakukan threshold tuning guna mendapatkan ambang keputusan terbaik yang meminimalkan False Negative dan meningkatkan F2-score.\n",
    "6. Menyimpan hasil pelatihan berupa model terbaik dengan nilai threshold optimal, dan metrik validasi agar dapat digunakan kembali pada tahap inference atau evaluasi lanjutan (`../outputs/models/`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73613369",
   "metadata": {},
   "source": [
    "## 1) Setup dan Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (246008, 18) Validation shape: (61503, 18)\n"
     ]
    }
   ],
   "source": [
    "# === Setup Umum ===\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, recall_score, precision_score, f1_score,\n",
    "                             precision_recall_curve, roc_curve)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    IMB = True\n",
    "except:\n",
    "    print('imbalanced-learn belum terinstal. Jalankan: !pip install imbalanced-learn')\n",
    "    IMB = False\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "RECALL_TARGET = 0.80\n",
    "\n",
    "DATA_PATH = Path('data/dataset_hasil_data_processing/train_processed.csv')\n",
    "MODEL_DIR = Path('outputs/models')\n",
    "METRIC_DIR = Path('outputs/metrics')\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "METRIC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "target_col = 'TARGET' if 'TARGET' in df.columns else [c for c in df.columns if c.lower() in ['target','label','y']][0]\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "train_idx, val_idx = next(sss.split(X, y))\n",
    "X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "print('Train shape:', X_train.shape, 'Validation shape:', X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training logistic_regression ===\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Best params: {'clf__C': 0.1}\n",
      "Saved model to outputs\\models\\logistic_regression\n",
      "{'recall': 0.6870090634441087, 'precision': 0.14836885602435843, 'f1': 0.2440350563405473, 'roc_auc': 0.7268325286093889, 'average_precision': 0.20326281221062686, 'threshold': 0.4889681203942051}\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "def tune_and_train(model, param_grid, model_name):\n",
    "    print(f'=== Training {model_name} ===')\n",
    "\n",
    "    steps = [\n",
    "        ('imp', SimpleImputer(strategy='median')),\n",
    "        ('scaler', RobustScaler()),\n",
    "    ]\n",
    "    if IMB:\n",
    "        steps.append(('smote', SMOTE(random_state=RANDOM_STATE)))\n",
    "    steps.append(('clf', model))\n",
    "\n",
    "    pipe = (ImbPipeline if IMB else Pipeline)(steps)\n",
    "\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=RANDOM_STATE)\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring='recall', cv=cv, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    print('Best params:', grid.best_params_)\n",
    "\n",
    "    # Threshold tuning (selaraskan panjang PR vs thresholds)\n",
    "    y_score = best_model.predict_proba(X_val)[:, 1]\n",
    "    prec, rec, thres = precision_recall_curve(y_val, y_score)\n",
    "    prec_, rec_ = prec[:-1], rec[:-1]\n",
    "    f2 = (5 * prec_ * rec_) / (4 * prec_ + rec_ + 1e-9)\n",
    "    thr = float(thres[int(np.argmax(f2))])\n",
    "\n",
    "    y_pred = (y_score >= thr).astype(int)\n",
    "    metrics = {\n",
    "        'recall': float(recall_score(y_val, y_pred)),\n",
    "        'precision': float(precision_score(y_val, y_pred, zero_division=0)),\n",
    "        'f1': float(f1_score(y_val, y_pred)),\n",
    "        'roc_auc': float(roc_auc_score(y_val, y_score)),\n",
    "        'average_precision': float(average_precision_score(y_val, y_score)),\n",
    "        'threshold': thr\n",
    "    }\n",
    "\n",
    "    # Simpan artefak\n",
    "    out_dir = MODEL_DIR / model_name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dump(best_model, out_dir / 'model.pkl')\n",
    "    json.dump({'threshold': thr}, open(out_dir / 'threshold.json', 'w'))\n",
    "    json.dump({'params': grid.best_params_, 'metrics': metrics}, open(out_dir / 'model_meta.json', 'w'), indent=2)\n",
    "    print('Saved model to', out_dir)\n",
    "    return metrics\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced', solver='lbfgs', random_state=RANDOM_STATE)\n",
    "params_lr = {'clf__C': [0.01, 0.1, 1, 10]}\n",
    "metrics_lr = tune_and_train(lr, params_lr, 'logistic_regression')\n",
    "print(metrics_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training random_forest ===\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "Best params: {'clf__max_depth': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 100}\n",
      "Saved model to outputs\\models\\random_forest\n",
      "{'recall': 0.7256797583081571, 'precision': 0.13564490625705897, 'f1': 0.22856599105528594, 'roc_auc': 0.7138943081602347, 'average_precision': 0.18478401824221657, 'threshold': 0.44096216937142707}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
    "params_rf = {\n",
    "    'clf__n_estimators': [100, 300],\n",
    "    'clf__max_depth': [5, 10, 20, None],\n",
    "    'clf__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "metrics_rf = tune_and_train(rf, params_rf, 'random_forest')\n",
    "print(metrics_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training gradient_boosting ===\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Best params: {'clf__learning_rate': 0.05, 'clf__max_depth': 2, 'clf__n_estimators': 100}\n",
      "Saved model to outputs\\models\\gradient_boosting\n",
      "{'recall': 0.675730110775428, 'precision': 0.14652574573088178, 'f1': 0.2408298040341684, 'roc_auc': 0.7223143453821236, 'average_precision': 0.19630379365265743, 'threshold': 0.43982455677979604}\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "params_gb = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'clf__max_depth': [2, 3, 4]\n",
    "}\n",
    "metrics_gb = tune_and_train(gb, params_gb, 'gradient_boosting')\n",
    "print(metrics_gb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
